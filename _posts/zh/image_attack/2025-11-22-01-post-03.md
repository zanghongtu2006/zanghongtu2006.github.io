---
layout: post
lang: zh
title: "第三章 · 白盒攻击深度解析（PGD / CW / AutoAttack）"
date: "2025-11-24 23:28:47"
slug: "ai-attack-and-secure-03"
translations:
  en: /en/ai-attack-and-secure-03/
  de: /de/ai-attack-and-secure-03/
categories: ["AI"]
tags: ["AI", "ATTACK"]
---
# 第三章 · 白盒攻击深度解析（PGD / CW / AutoAttack）

白盒攻击（White-Box Attack）指攻击者**完全能访问模型内部结构与梯度信息**。  
这是最强、最直接、也最容易实现的攻击方式，也是研究对抗鲁棒性的基础。

本章将深入解释白盒攻击的数学逻辑、梯度原理，以及几类代表性算法的完整构造方法。

---

#  1. 为什么白盒攻击如此强大？

因为攻击者可以直接访问：

- 模型参数 \( \theta \)  
- 计算图（computational graph）  
- 损失函数 \( L \)  
- 对输入的梯度 \( \nabla_x L \)

这意味着攻击者可以直接计算：

\[
\delta = f(\nabla_x L)
\]

然后精确找到：

> **最能欺骗模型的输入方向。**

就像拿到了“模型的弱点地图”。

这也是为什么白盒攻击被视为：

> 测量模型“理论鲁棒性上限”的方法。

---

#  2. FGSM：最基础也最经典的一步攻击

FGSM（Fast Gradient Sign Method）由 Goodfellow 在 2014 年提出。

核心思想非常简单：

> 沿梯度方向走一步，让 loss 最大化。

公式：

\[
x' = x + \epsilon \cdot \text{sign}(\nabla_x L(f(x), y))
\]

特点：

- 速度极快（只需一次反向传播）
- 良好的攻击成功率
- 但容易被防御（如对抗训练）

⚠️ 可视化效果：  
FGSM 通常会生成高频噪声，看起来不自然，但模型仍很容易被误导。

---

#  3. BIM / I-FGSM：迭代版 FGSM

为了让 FGSM 更强，出现了 BIM（Basic Iterative Method）：

\[
x_{t+1} = \text{clip}_\epsilon\left[
x_t + \alpha \cdot \text{sign}(\nabla_x L(x_t))
\right]
\]

特点：

- 初始攻击更强
- 逐步逼近 decision boundary
- 能穿透大多数简单防御

BIM 也被称作 I-FGSM。

---

#  4. PGD：目前工业界事实上的“最强基础攻击”

PGD（Projected Gradient Descent）可以看作 BIM + 随机初始化。

完整公式：

1. 随机初始化：

\[
x_0 = x + \text{Uniform}(-\epsilon, +\epsilon)
\]

2. 多步迭代攻击：

\[
x_{t+1} = \Pi_{B_\epsilon(x)}\left[
x_t + \alpha \cdot \text{sign}(\nabla_x L(x_t))
\right]
\]

其中 \( \Pi \) 为“投影操作”，保证扰动仍在 \(\epsilon\) 范围内。

PGD 的特点：

- 能找到更加全局最优的对抗样本
- 被 Madry Lab 称作“最强一阶攻击”
- 对抗训练里使用 PGD 可以极大提升鲁棒性

事实上，PGD 被认为是：

> “模型能抵抗 PGD，才有资格说自己鲁棒。”

---

#  5. C&W Attack：最著名的二阶优化对抗攻击

Carlini & Wagner（C&W）攻击是 2017 年提出的，对抗样本领域最重要的论文之一。

核心思想：

> 直接优化扰动 δ，使攻击成功且 δ 尺寸最小。

优化目标：

\[
\min_\delta \|\delta\|_2 + c \cdot f(x+\delta)
\]

其中：

- \(\|\delta\|_2\)：扰动大小（目标最小）  
- \(f(x+\delta)\)：分类错误程度的损失（目标最大）  
- \(c\)：平衡项  

C&W 特点：

- 非常稳定
- 噪声自然
- 成功率高
- 至今依然强大

它常被用来检验模型是否存在 **梯度遮蔽**（下一章会讲）。

---

#  6. DeepFool：几何角度的攻击

DeepFool 的思路不是沿梯度走，而是：

> 逼近分类边界，然后跨过去。

假设分类边界是线性的（在局部区域近似成立）：

\[
x' = x + \frac{|f(x)|}{\|\nabla_x f(x)\|_2^2} \cdot \nabla_x f(x)
\]

DeepFool 的扰动通常极小，非常难察觉。

---

#  7. EOT（Expectation over Transformation）攻击

当输入会经过随机变换（resize / crop / augmentation）时，梯度方向变得不稳定。

EOT 的思想：

> 对多个随机变换取梯度期望，使攻击在随机变换后仍然有效。

\[
\nabla_x L = \mathbb{E}_{t\sim T} \left[\nabla_x L(f(t(x)), y)\right]
\]

适用于：

- 随机防御
- 实物攻击（物理世界扰动）
- 任意随机增强 pipeline

---

#  8. LPIPS Attack（感知空间的 PGD）

传统攻击在像素空间扰动。  
LPIPS Attack 则在**感知空间**（特征空间）优化：

\[
\text{LPIPS}(x, x') < \epsilon
\]

它可以生成：

- 高度真实
- 几乎看不出差别

的对抗图像。

非常适合实物攻击与真实世界应用。

---

#  9. AutoAttack（完全自动、可靠的攻击组合）

AutoAttack 是工业界常用的自动攻击基线。  
由四部分组成：

1. **APGD-CE**（PGD + 有序 CE）  
2. **APGD-DLR**（更稳定的 loss）  
3. **FAB Attack**  
4. **Square Attack**（黑盒部分）

AutoAttack 的优点：

- 不需要调参  
- 可靠 & 稳定  
- “安全模型的试金石”

现在做鲁棒性 benchmark，AutoAttack 基本是默认流程。

---

#  10. 梯度遮蔽（Gradient Masking）现象

许多模型在经过一些“防御”后：

- FGSM 不行了  
- PGD 不行了  
- C&W 不行了  

但其鲁棒性并没有真正变强，而是：

> 模型让梯度无效了。

典型情况：

- 激活函数饱和  
- 非可导操作  
- 梯度爆炸/消失  
- 随机化操作  
- 输入被离散化  

要检验是否存在遮蔽，需要：

- 多种攻击测试  
- 包含黑盒攻击  
- 包含 C&W 和 AutoAttack  

后续章节会更详细分析。

---

#  11. 白盒攻击的能力边界

白盒攻击能做到的：

- 找最脆弱方向  
- 非常小的扰动  
- 高成功率  
- 可精确控制扰动大小  
- 评测模型鲁棒性的“最强参考线”

做不到的：

- 不能直接用于黑盒部署环境（需要梯度）  
- 某些随机化、离散化 pipeline 会让梯度不稳定  
- 无法解决物理世界随机性（但可用 EOT）  

---

#  12. 本章小结

本章介绍了白盒攻击的完整系统：

| 方法 | 本质 | 优点 | 典型用途 |
|------|------|------|-----------|
| **FGSM** | 一步梯度 | 快 | baseline |
| **BIM / I-FGSM** | 迭代 FGSM | 强 | 简单对抗训练 |
| **PGD** | 随机初始化 + 多步迭代 | 最强一阶攻击 | 标准鲁棒性评测 |
| **C&W** | 优化扰动大小 | 非常强 | 检测梯度遮蔽 |
| **DeepFool** | 逼近边界 | 扰动最小 | 白盒分析 |
| **LPIPS Attack** | 特征空间 | 极自然 | 真实世界攻击 |
| **EOT** | 随机增强平均梯度 | 抗随机性 | 实物攻击 |
| **AutoAttack** | 自动攻击组合 | 稳定可靠 | benchmark 标准 |

白盒攻击既是对抗样本的基础，也是所有鲁棒性研究的核心。

下章将继续讲**黑盒攻击**与“如何在不知道梯度的情况下推测出最能欺骗模型的输入方向”。
