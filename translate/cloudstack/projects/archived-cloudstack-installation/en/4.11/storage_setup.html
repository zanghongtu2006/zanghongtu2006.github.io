<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>存储配置 &#8212; CloudStack 安装手册 4.11.0.0 documentation</title>
    <link rel="stylesheet" href="_static/basic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="https://media.readthedocs.org/css/badge_only.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootswatch-3.2.0/spacelab/bootstrap.min.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-2.0.3.min.js"></script>
    <script type="text/javascript" src="https://media.readthedocs.org/javascript/jquery/jquery-migrate-1.2.1.min.js"></script>
    <script type="text/javascript" src="https://media.readthedocs.org/javascript/underscore.js"></script>
    <script type="text/javascript" src="https://media.readthedocs.org/javascript/doctools.js"></script>
    <script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-doc-embed.js"></script>
    <script type="text/javascript" src="_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="_static/bootstrap-3.2.0/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="_static/bootstrap-sphinx.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="其它安装选项" href="optional_installation.html" />
    <link rel="prev" title="网络配置" href="network_setup.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  
<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="storage_setup.html" />

<link rel="stylesheet" href="https://media.readthedocs.org/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="_static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = 'storage_setup'
READTHEDOCS_DATA['source_suffix'] = '.rst'
</script>

<script type="text/javascript" src="https://media.readthedocs.org/javascript/readthedocs-analytics.js"></script>

<!-- end RTD <extrahead> -->
</head><body>

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          安装指南</a>
        <span class="navbar-text navbar-version pull-left"><b>4.11</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
                <a role="button"
                   id="dLabelGlobalToc"
                   data-toggle="dropdown"
                   data-target="#"
                   href="index.html">Sections <b class="caret"></b></a>
                <ul class="dropdown-menu globaltoc"
                    role="menu"
                    aria-labelledby="dLabelGlobalToc">
                     <ul>
<li class="toctree-l1"><a class="reference internal" href="choosing_deployment_architecture.html">架构选型</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="qig.html">快速入门指南 for CentOS 6</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="building_from_source.html">从源码编译安装</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview/index.html">安装概述</a></li>
<li class="toctree-l1"><a class="reference internal" href="management-server/index.html">安装管理服务</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">安装配置 CloudStack </a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="hypervisor/hyperv.html">Hyper-V 安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypervisor/kvm.html">KVM 安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypervisor/lxc.html">LXC 安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypervisor/vsphere.html">VMware vSphere 安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="hypervisor/xenserver.html">Citrix XenServer 安装</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="network_setup.html">网络配置</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="storage_setup.html#">存储配置</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage_setup.html#small-scale-setup">Small-Scale Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage_setup.html#large-scale-setup">Large-Scale Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage_setup.html#storage-architecture">存储架构</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage_setup.html#network-configuration-for-storage">Network Configuration For Storage</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="optional_installation.html">其它安装选项</a></li>
<li class="toctree-l1"><a class="reference internal" href="encryption.html">密码和加密密钥</a></li>
</ul>


                </ul>
              </li>
              
                
              
            
            
              
                
  <li>
    <a href="network_setup.html" title="Previous Chapter: 网络配置"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; 网络配置</span>
    </a>
  </li>
  <li>
    <a href="optional_installation.html" title="Next Chapter: 其它安装选项"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">其它安装选项 &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="storage_setup.html#">存储配置</a><ul>
<li><a class="reference internal" href="storage_setup.html#primary-storage">主存储</a></li>
<li><a class="reference internal" href="storage_setup.html#secondary-storage">二级存储</a></li>
</ul>
</li>
<li><a class="reference internal" href="storage_setup.html#small-scale-setup">Small-Scale Setup</a></li>
<li><a class="reference internal" href="storage_setup.html#large-scale-setup">Large-Scale Setup</a></li>
<li><a class="reference internal" href="storage_setup.html#storage-architecture">存储架构</a><ul>
<li><a class="reference internal" href="storage_setup.html#local-storage">Local Storage</a></li>
<li><a class="reference internal" href="storage_setup.html#traditional-node-based-shared-storage">‘Traditional’ node-based Shared Storage</a></li>
<li><a class="reference internal" href="storage_setup.html#clustered-shared-storage">Clustered Shared Storage</a></li>
</ul>
</li>
<li><a class="reference internal" href="storage_setup.html#network-configuration-for-storage">Network Configuration For Storage</a><ul>
<li><a class="reference internal" href="storage_setup.html#cloudstack-networking-for-storage">CloudStack 存储网络</a></li>
<li><a class="reference internal" href="storage_setup.html#small-scale-example-configurations">Small-Scale Example Configurations</a><ul>
<li><a class="reference internal" href="storage_setup.html#linux-nfs-on-local-disks-and-das">Linux NFS on Local Disks and DAS</a></li>
<li><a class="reference internal" href="storage_setup.html#linux-nfs-on-iscsi">Linux NFS on iSCSI</a></li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    <div class="col-md-9">
      
  <div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>NOTICE: THIS DOCUMENTATION SITE HAS BEEN SUPERSEDED.</p>
<p class="last">For the current documentation site goto: <a class="reference external" href="../../../../index.html">http://docs.cloudstack.apache.org</a></p>
</div>
<div class="section" id="storage-setup">
<h1>存储配置<a class="headerlink" href="storage_setup.html#storage-setup" title="Permalink to this headline">¶</a></h1>
<div class="section" id="primary-storage">
<h2>主存储<a class="headerlink" href="storage_setup.html#primary-storage" title="Permalink to this headline">¶</a></h2>
<p>CloudStack is designed to work with a wide variety of commodity and enterprise-rated storage systems.
CloudStack can also leverage the local disks within the hypervisor hosts if supported by the selected
hypervisor. Storage type support for guest virtual disks differs based on hypervisor selection.</p>
<table border="1" class="docutils">
<colgroup>
<col width="14%" />
<col width="31%" />
<col width="19%" />
<col width="36%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Storage Type</th>
<th class="head">XenServer</th>
<th class="head">vSphere</th>
<th class="head">KVM</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>NFS</td>
<td>Supported</td>
<td>Supported</td>
<td>Supported</td>
</tr>
<tr class="row-odd"><td>iSCSI</td>
<td>Supported</td>
<td>Supported via VMFS</td>
<td>Supported via Clustered Filesystems</td>
</tr>
<tr class="row-even"><td>Fiber Channel</td>
<td>Supported via Pre-existing SR</td>
<td>Supported</td>
<td>Supported via Clustered Filesystems</td>
</tr>
<tr class="row-odd"><td>Local Disk</td>
<td>Supported</td>
<td>Supported</td>
<td>Supported</td>
</tr>
</tbody>
</table>
<p>The use of the 集群 Logical Volume Manager (CLVM) for KVM is not officially supported with
CloudStack.</p>
</div>
<div class="section" id="secondary-storage">
<h2>二级存储<a class="headerlink" href="storage_setup.html#secondary-storage" title="Permalink to this headline">¶</a></h2>
<p>CloudStack is designed to work with any scalable secondary storage system. The only requirement is
that the secondary storage system supports the NFS protocol. For large, multi-zone deployments, S3
compatible storage is also supported for secondary storage. This allows for secondary storage which can
span an entire region, however an NFS staging area must be maintained in each zone as most hypervisors
are not capable of directly mounting S3 type storage.</p>
</div>
</div>
<div class="section" id="small-scale-setup">
<h1>Small-Scale Setup<a class="headerlink" href="storage_setup.html#small-scale-setup" title="Permalink to this headline">¶</a></h1>
<p>In a small-scale setup, a single NFS server can function as both primary and secondary storage. The NFS
server must export two separate shares, one for primary storage and the other for secondary storage. This
could be a VM or physical host running an NFS service on a Linux OS or a virtual software appliance. Disk
and network performance are still important in a small scale setup to get a good experience when deploying,
running or snapshotting VMs.</p>
</div>
<div class="section" id="large-scale-setup">
<h1>Large-Scale Setup<a class="headerlink" href="storage_setup.html#large-scale-setup" title="Permalink to this headline">¶</a></h1>
<p>In large-scale environments primary and secondary storage typically consist of independent physical storage arrays.</p>
<p>Primary storage is likely to have to support mostly random read/write I/O once a template has been
deployed.  Secondary storage is only going to experience sustained sequential reads or writes.</p>
<p>In clouds which will experience a large number of users taking snapshots or deploying VMs at the
same time, secondary storage performance will be important to maintain a good user experience.</p>
<p>It is important to start the design of your storage with the a rough profile of the workloads which it will
be required to support. Care should be taken to consider the IOPS demands of your guest VMs as much as the
volume of data to be stored and the bandwidth (MB/s) available at the storage interfaces.</p>
</div>
<div class="section" id="storage-architecture">
<h1>存储架构<a class="headerlink" href="storage_setup.html#storage-architecture" title="Permalink to this headline">¶</a></h1>
<p>There are many different storage types available which are generally suitable for CloudStack environments.
Specific use cases should be considered when deciding the best one for your environment and financial
constraints often make the ‘perfect’ storage architecture economically unrealistic.</p>
<p>Broadly, the architectures of the available primary storage types can be split into 3 types:</p>
<div class="section" id="local-storage">
<h2>Local Storage<a class="headerlink" href="storage_setup.html#local-storage" title="Permalink to this headline">¶</a></h2>
<p>Local storage works best for pure ‘cloud-era’ workloads which rarely need to be migrated between storage
pools and where HA of individual VMs is not required. As SSDs become more mainstream/affordable, local
storage based VMs can now be served with the size of IOPS which previously could only be generated by
large arrays with 10s of spindles. Local storage is highly scalable because as you add hosts you would
add the same proportion of storage. Local Storage is relatively inefficent as it can not take advantage
of linked clones or any deduplication.</p>
</div>
<div class="section" id="traditional-node-based-shared-storage">
<h2>‘Traditional’ node-based Shared Storage<a class="headerlink" href="storage_setup.html#traditional-node-based-shared-storage" title="Permalink to this headline">¶</a></h2>
<p>Traditional node-based storage are arrays which consist of a controller/controller pair attached to a
number of disks in shelves.
Ideally a cloud architecture would have one of these physical arrays per CloudStack pod to limit the
‘blast-radius’ of a failure to a single pod.  This is often not economically viable, however one should
look to try to reduce the scale of any incident relative to any zone with any single array where
possible.
The use of shared storage enables workloads to be immediately restarted on an alternate host should a
host fail. These shared storage arrays often have the ability to create ‘tiers’ of storage utilising
say large SATA disks, 15k SAS disks and SSDs. These differently performing tiers can then be presented as
different offerings to users.
The sizing of an array should take into account the IOPS required by the workload as well as the volume
of data to be stored.  One should also consider the number of VMs which a storage array will be expected
to support, and the maximum network bandwidth possible through the controllers.</p>
</div>
<div class="section" id="clustered-shared-storage">
<h2>Clustered Shared Storage<a class="headerlink" href="storage_setup.html#clustered-shared-storage" title="Permalink to this headline">¶</a></h2>
<p>Clustered shared storage arrays are the new generation of storage which do not have a single set of
interfaces where data enters and exits the array.  Instead it is distributed between all of the active
nodes giving greatly improved scalability and performance.  Some shared storage arrays enable all data
to continue to be accessible even in the event of the loss of an entire node.</p>
<p>The network topology should be carefully considered when using clustered shared storage to avoid creating
bottlenecks in the network fabric.</p>
</div>
</div>
<div class="section" id="network-configuration-for-storage">
<h1>Network Configuration For Storage<a class="headerlink" href="storage_setup.html#network-configuration-for-storage" title="Permalink to this headline">¶</a></h1>
<p>Care should be taken when designing your cloud to take into consideration not only the performance
of your disk arrays but also the bandwidth available to move that traffic between the switch fabric and
the array interfaces.</p>
<div class="section" id="cloudstack-networking-for-storage">
<h2>CloudStack 存储网络<a class="headerlink" href="storage_setup.html#cloudstack-networking-for-storage" title="Permalink to this headline">¶</a></h2>
<p>The first thing to understand is the process of provisioning primary storage. When you create a primary
storage pool for any given cluster, the CloudStack management server tells each hosts’ hypervisor to
mount the NFS share or (iSCSI LUN). The storage pool will be presented within the hypervisor as a
datastore (VMware), storage repository (XenServer/XCP) or a mount point (KVM), the important point is
that it is the hypervisor itself that communicates with the primary storage, the CloudStack management
server only communicates with the host hypervisor. Now, all hypervisors communicate with the outside
world via some kind of management interface – think VMKernel port on ESXi or ‘Management Interface’ on
XenServer. As the CloudStack management server needs to communicate with the hypervisor in the host,
this management interface must be on the CloudStack ‘management’ or ‘private’ network.  There may be
other interfaces configured on your host carrying guest and public traffic to/from VMs within the hosts
but the hypervisor itself doesn’t/can’t communicate over these interfaces.</p>
<p><img alt="hypervisor storage communication" src="_images/hypervisorcomms.png" />
<em>Figure 1</em>: Hypervisor communications</p>
<p>Separating 主存储 traffic
For those from a pure virtualisation background, the concept of creating a specific interface for storage
traffic will not be new; it has long been best practice for iSCSI traffic to have a dedicated switch
fabric to avoid any latency or contention issues.
Sometimes in the cloud(Stack) world we forget that we are simply orchestrating processes that the
hypervisors already carry out and that many ‘normal’ hypervisor configurations still apply.
The logical reasoning which explains how this splitting of traffic works is as follows:</p>
<ol class="arabic simple">
<li>If you want an additional interface over which the hypervisor can communicate (excluding teamed or bonded interfaces) you need to give it an IP address.</li>
<li>The mechanism to create an additional interface that the hypervisor can use is to create an additional management interface</li>
<li>So that the hypervisor can differentiate between the management interfaces they have to be in different (non-overlapping) subnets</li>
<li>In order for the ‘primary storage’ management interface to communicate with the primary storage, the interfaces on the primary storage arrays must be in the same CIDR as the ‘primary storage’ management interface.</li>
<li>Therefore the primary storage must be in a different subnet to the management network</li>
</ol>
<p><img alt="subnetted storage interfaces" src="_images/subnetting_storage.png" />
<em>Figure 2</em>: Subnetting of Storage Traffic</p>
<p><img alt="hypervisor communications to secondary storage" src="_images/hypervisorcomms-secstorage.png" />
<em>Figure 3</em>: Hypervisor Communications with Separated Storage Traffic</p>
<p>Other 主存储 Types
If you are using PreSetup or SharedMountPoints to connect to IP based storage then the same principles
apply; if the primary storage and ‘primary storage interface’ are in a different subnet to the ‘management
subnet’ then the hypervisor will use the ‘primary storage interface’ to communicate with the primary
storage.</p>
</div>
<div class="section" id="small-scale-example-configurations">
<h2>Small-Scale Example Configurations<a class="headerlink" href="storage_setup.html#small-scale-example-configurations" title="Permalink to this headline">¶</a></h2>
<p>In this section we go through a few examples of how to set up storage to
work properly on a few types of NFS and iSCSI storage systems.</p>
<div class="section" id="linux-nfs-on-local-disks-and-das">
<h3>Linux NFS on Local Disks and DAS<a class="headerlink" href="storage_setup.html#linux-nfs-on-local-disks-and-das" title="Permalink to this headline">¶</a></h3>
<p>This section describes how to configure an NFS export on a standard
Linux installation. The exact commands might vary depending on the
operating system version.</p>
<ol class="arabic">
<li><p class="first">Install the RHEL/CentOS distribution on the storage server.</p>
</li>
<li><p class="first">If the root volume is more than 2 TB in size, create a smaller boot
volume to install RHEL/CentOS. A root volume of 20 GB should be
sufficient.</p>
</li>
<li><p class="first">After the system is installed, create a directory called /export.
This can each be a directory in the root partition itself or a mount
point for a large disk volume.</p>
</li>
<li><p class="first">If you have more than 16TB of storage on one host, create multiple
EXT3 file systems and multiple NFS exports. Individual EXT3 file
systems cannot exceed 16TB.</p>
</li>
<li><p class="first">After /export directory is created, run the following command to
configure it as an NFS export.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># echo &quot;/export &lt;CIDR&gt;(rw,async,no_root_squash,no_subtree_check)&quot; &gt;&gt; /etc/exports</span>
</pre></div>
</div>
<p>Adjust the above command to suit your deployment needs.</p>
</li>
</ol>
<ul class="simple">
<li><strong>Limiting NFS export.</strong> It is highly recommended that you limit the NFS export to a particular subnet by specifying a subnet mask (e.g.,”192.168.1.0/24”). By allowing access from only within the expected cluster, you avoid having non-pool member mount the storage. The limit you place must include the management network(s) and the storage network(s). If the two are the same network then one CIDR is sufficient. If you have a 独立存储网络 you must provide separate CIDR’s for both or one CIDR that is broad enough to span both.</li>
</ul>
<blockquote>
<div><p>The following is an example with separate CIDRs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>/export <span class="m">192</span>.168.1.0/24<span class="o">(</span>rw,async,no_root_squash,no_subtree_check<span class="o">)</span> <span class="m">10</span>.50.1.0/24<span class="o">(</span>rw,async,no_root_squash,no_subtree_check<span class="o">)</span>
</pre></div>
</div>
</div></blockquote>
<ul class="simple">
<li><strong>Removing the async flag.</strong> The async flag improves performance by allowing the NFS server to respond before writes are committed to the disk. Remove the async flag in your mission critical production deployment.</li>
</ul>
<ol class="arabic" start="6">
<li><p class="first">Run the following command to enable NFS service.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># chkconfig nfs on</span>
</pre></div>
</div>
</li>
<li><p class="first">Edit the /etc/sysconfig/nfs file and uncomment the following lines.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nv">LOCKD_TCPPORT</span><span class="o">=</span><span class="m">32803</span>
<span class="nv">LOCKD_UDPPORT</span><span class="o">=</span><span class="m">32769</span>
<span class="nv">MOUNTD_PORT</span><span class="o">=</span><span class="m">892</span>
<span class="nv">RQUOTAD_PORT</span><span class="o">=</span><span class="m">875</span>
<span class="nv">STATD_PORT</span><span class="o">=</span><span class="m">662</span>
<span class="nv">STATD_OUTGOING_PORT</span><span class="o">=</span><span class="m">2020</span>
</pre></div>
</div>
</li>
<li><p class="first">Edit the /etc/sysconfig/iptables file and add the following lines at
the beginning of the INPUT chain.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>-A INPUT -m state --state NEW -p udp --dport <span class="m">111</span> -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport <span class="m">111</span> -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport <span class="m">2049</span> -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport <span class="m">32803</span> -j ACCEPT
-A INPUT -m state --state NEW -p udp --dport <span class="m">32769</span> -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport <span class="m">892</span> -j ACCEPT
-A INPUT -m state --state NEW -p udp --dport <span class="m">892</span> -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport <span class="m">875</span> -j ACCEPT
-A INPUT -m state --state NEW -p udp --dport <span class="m">875</span> -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport <span class="m">662</span> -j ACCEPT
-A INPUT -m state --state NEW -p udp --dport <span class="m">662</span> -j ACCEPT
</pre></div>
</div>
</li>
<li><p class="first">Reboot the server.</p>
<p>An NFS share called /export is now set up.</p>
</li>
</ol>
<div class="admonition note">
<p class="first admonition-title">提示</p>
<p class="last">When copying and pasting a command, be sure the command has pasted as a single line before executing. Some document viewers may introduce unwanted line breaks in copied text.</p>
</div>
</div>
<div class="section" id="linux-nfs-on-iscsi">
<h3>Linux NFS on iSCSI<a class="headerlink" href="storage_setup.html#linux-nfs-on-iscsi" title="Permalink to this headline">¶</a></h3>
<p>Use the following steps to set up a Linux NFS server export on an iSCSI
volume. These steps apply to RHEL/CentOS 5 distributions.</p>
<ol class="arabic">
<li><p class="first">Install iscsiadm.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># yum install iscsi-initiator-utils</span>
<span class="c1"># service iscsi start</span>
<span class="c1"># chkconfig --add iscsi</span>
<span class="c1"># chkconfig iscsi on</span>
</pre></div>
</div>
</li>
<li><p class="first">Discover the iSCSI target.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># iscsiadm -m discovery -t st -p &lt;iSCSI Server IP address&gt;:3260</span>
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># iscsiadm -m discovery -t st -p 172.23.10.240:3260 172.23.10.240:3260,1 iqn.2001-05.com.equallogic:0-8a0906-83bcb3401-16e0002fd0a46f3d-rhel5-test</span>
</pre></div>
</div>
</li>
<li><p class="first">Log in.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># iscsiadm -m node -T &lt;Complete Target Name&gt; -l -p &lt;Group IP&gt;:3260</span>
</pre></div>
</div>
<p>For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># iscsiadm -m node -l -T iqn.2001-05.com.equallogic:83bcb3401-16e0002fd0a46f3d-rhel5-test -p 172.23.10.240:3260</span>
</pre></div>
</div>
</li>
<li><p class="first">Discover the SCSI disk. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># iscsiadm -m session -P3 | grep Attached</span>
Attached scsi disk sdb State: running
</pre></div>
</div>
</li>
<li><p class="first">Format the disk as ext3 and mount the volume.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="c1"># mkfs.ext3 /dev/sdb</span>
<span class="c1"># mkdir -p /export</span>
<span class="c1"># mount /dev/sdb /export</span>
</pre></div>
</div>
</li>
<li><p class="first">Add the disk to /etc/fstab to make sure it gets mounted on boot.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>/dev/sdb /export ext3 _netdev <span class="m">0</span> <span class="m">0</span>
</pre></div>
</div>
</li>
</ol>
<p>Now you can set up /export as an NFS share.</p>
<ul>
<li><p class="first"><strong>Limiting NFS export.</strong> In order to avoid data loss, it is highly
recommended that you limit the NFS export to a particular subnet by
specifying a subnet mask (e.g.,”192.168.1.0/24”). By allowing access
from only within the expected cluster, you avoid having non-pool
member mount the storage and inadvertently delete all its data. The
limit you place must include the management network(s) and the
storage network(s). If the two are the same network then one CIDR is
sufficient. If you have a 独立存储网络 you must provide
separate CIDRs for both or one CIDR that is broad enough to span
both.</p>
<p>The following is an example with separate CIDRs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>/export <span class="m">192</span>.168.1.0/24<span class="o">(</span>rw,async,no_root_squash,no_subtree_check<span class="o">)</span> <span class="m">10</span>.50.1.0/24<span class="o">(</span>rw,async,no_root_squash,no_subtree_check<span class="o">)</span>
</pre></div>
</div>
</li>
<li><p class="first"><strong>Removing the async flag.</strong> The async flag improves performance by
allowing the NFS server to respond before writes are committed to the
disk. Remove the async flag in your mission critical production
deployment.</p>
</li>
</ul>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="storage_setup.html#">Back to top</a>
          | <a href="network_setup.html" title="Previous Chapter: 网络配置"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; 网络配置</span>
          </a>
          | <a href="optional_installation.html" title="Next Chapter: 其它安装选项"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">其它安装选项 &raquo;</span>
          </a>
      
        <br/>
        
<div id="sourcelink">
  <a href="_sources/storage_setup.rst.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2018, Apache Software Foundation.<br/>
    </p>
  </div>
</footer>
  </body>
</html>