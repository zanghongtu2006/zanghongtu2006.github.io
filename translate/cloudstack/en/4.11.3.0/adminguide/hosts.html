

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>添加主机 &mdash; Apache CloudStack 4.11.3.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../static/documentation_options.js"></script>
        <script type="text/javascript" src="../static/jquery.js"></script>
        <script type="text/javascript" src="../static/underscore.js"></script>
        <script type="text/javascript" src="../static/doctools.js"></script>
        <script type="text/javascript" src="../static/language_data.js"></script>
        <script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-doc-embed.js"></script>
    
    <script type="text/javascript" src="../static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="存储概述" href="storage.html" />
    <link rel="prev" title="创建模板: 概述" href="templates.html" /> 

<!-- RTD Extra Head -->

<!-- 
Always link to the latest version, as canonical.
http://docs.readthedocs.org/en/latest/canonical.html
-->
<link rel="canonical" href="../../latest/adminguide/hosts.html" />

<link rel="stylesheet" href="https://assets.readthedocs.org/static/css/readthedocs-doc-embed.css" type="text/css" />

<script type="text/javascript" src="../static/readthedocs-data.js"></script>

<!-- Add page-specific data, which must exist in the page js, not global -->
<script type="text/javascript">
READTHEDOCS_DATA['page'] = "adminguide/hosts"
READTHEDOCS_DATA['source_suffix'] = ".rst"
</script>

<script type="text/javascript" src="https://assets.readthedocs.org/static/javascript/readthedocs-analytics.js"></script>

<!-- end RTD <extrahead> -->
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> Apache CloudStack
          

          
          </a>

          
            
            
            
              <div class="version">
                4.11.3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">目录:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../conceptsandterminology/index.html">CloudStack 概念和术语</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickinstallationguide/qig.html">快速入门指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installguide/index.html">安装指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../upgrading/index.html">升级 CloudStack</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">使用手册</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#user-interface">用户界面</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#managing-accounts-users-and-domains">账户、用户和域</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#using-projects-to-organize-user-resources">用项目来管理用户资源</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#service-offerings">计算方案</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#setting-up-networking-for-users">设置用户网络</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#working-with-virtual-machines">虚拟机</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#working-with-templates">模板</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#working-with-hosts">主机</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="hosts.html#">添加主机</a></li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#scheduled-maintenance-and-maintenance-mode-for-hosts">Scheduled Maintenance and Maintenance Mode for Hosts</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#vcenter-and-maintenance-mode">vCenter and Maintenance Mode</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#xenserver-and-maintenance-mode">XenServer and Maintenance Mode</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#disabling-and-enabling-zones-pods-and-clusters">资源域、池和集群的启用和禁用</a></li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#removing-hosts">删除主机</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#removing-xenserver-and-kvm-hosts">Removing XenServer and KVM Hosts</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#removing-vsphere-hosts">Removing vSphere Hosts</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#re-installing-hosts">Re-Installing Hosts</a></li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#maintaining-hypervisors-on-hosts">Maintaining Hypervisors on Hosts</a></li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#changing-host-password">修改主机密码</a></li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#over-provisioning-and-service-offering-limits">Over-Provisioning and Service Offering Limits</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#limitations-on-over-provisioning-in-xenserver-and-kvm">Limitations on Over-Provisioning in XenServer and KVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#requirements-for-over-provisioning">Requirements for Over-Provisioning</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#setting-over-provisioning-ratios">Setting Over-Provisioning Ratios</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#service-offering-limits-and-over-provisioning">Service Offering Limits and Over-Provisioning</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#vlan-provisioning">VLAN Provisioning</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#vlan-allocation-example">VLAN 划分示例</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#adding-non-contiguous-vlan-ranges">Adding Non Contiguous VLAN Ranges</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#assigning-vlans-to-isolated-networks">Assigning VLANs to Isolated Networks</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#out-of-band-management">Out-of-band Management</a></li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#security">安全</a></li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#server-address-usage">Server Address Usage</a></li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#securing-process">Securing Process</a></li>
<li class="toctree-l3"><a class="reference internal" href="hosts.html#kvm-libvirt-hook-script-include">KVM Libvirt Hook Script Include</a><ul>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#feature-overview">Feature 概述</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#the-kvm-libvirt-hook-script-allows-for">The KVM Libvirt Hook script allows for</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#usage">Usage</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#timeout-configuration">Timeout Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#custom-script-naming-for-a-specific-vm-action">Custom Script Naming for a Specific VM Action</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#custom-script-naming-for-all-vm-actions">Custom Script Naming for All VM Actions</a></li>
<li class="toctree-l4"><a class="reference internal" href="hosts.html#custom-script-execution-configuration">Custom Script Execution Configuration</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#working-with-storage">存储</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#working-with-system-virtual-machines">系统虚拟机</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#working-with-usage">Working with Usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#managing-networks-and-traffic">Managing Networks and Traffic</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#managing-the-cloud">管理云</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#system-reliability-and-availability">系统的可靠性和可用性</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#tuning">调优</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#events-and-troubleshooting">Events and Troubleshooting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../developersguide/index.html">开发者手册</a></li>
<li class="toctree-l1"><a class="reference internal" href="../plugins/index.html">插件使用手册</a></li>
<li class="toctree-l1"><a class="reference internal" href="../releasenotes/index.html">发行版本说明</a></li>
</ul>
<p class="caption"><span class="caption-text">其它:</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="http://cloudstack.apache.org/api.html">API 文档</a></li>
<li class="toctree-l1"><a class="reference external" href="https://cwiki.apache.org/confluence/display/CLOUDSTACK/Home">Apache CloudStack Wiki</a></li>
<li class="toctree-l1"><a class="reference external" href="http://cloudstack.apache.org/">Apache CloudStack 官网</a></li>
<li class="toctree-l1"><a class="reference external" href="http://cloudstack.apache.org/downloads.html">Apache CloudStack 源码</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/apache/cloudstack">Apache CloudStack on GitHub</a></li>
</ul>
<p class="caption"><span class="caption-text">Pre 4.11 Documentation:</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="../../../projects/cloudstack-installation.html">安装指南</a></li>
<li class="toctree-l1"><a class="reference external" href="../../../projects/cloudstack-administration.html">管理员手册</a></li>
<li class="toctree-l1"><a class="reference external" href="../../../projects/cloudstack-release-notes.html">发行版本说明</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Apache CloudStack</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">使用手册</a> &raquo;</li>
        
      <li>添加主机</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/apache/cloudstack-documentation/blob/4.11.3.0/source/adminguide/hosts.rst" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="adding-hosts">
<h1>添加主机<a class="headerlink" href="hosts.html#adding-hosts" title="Permalink to this headline">¶</a></h1>
<p>可以随时通过增加主机来增加来宾虚拟机的容量。 For requirements and instructions, see <a class="reference internal" href="../installguide/configuration.html#adding-a-host"><span class="std std-ref">Adding a Host</span></a>.</p>
</div>
<div class="section" id="scheduled-maintenance-and-maintenance-mode-for-hosts">
<h1>Scheduled Maintenance and Maintenance Mode for Hosts<a class="headerlink" href="hosts.html#scheduled-maintenance-and-maintenance-mode-for-hosts" title="Permalink to this headline">¶</a></h1>
<p>You can place a host into maintenance mode. When maintenance mode is
activated, the host becomes unavailable to receive new guest VMs, and
the guest VMs already running on the host are seamlessly migrated to
another host not in maintenance mode. This migration uses live migration
technology and does not interrupt the execution of the guest.</p>
<div class="section" id="vcenter-and-maintenance-mode">
<h2>vCenter and Maintenance Mode<a class="headerlink" href="hosts.html#vcenter-and-maintenance-mode" title="Permalink to this headline">¶</a></h2>
<p>To enter maintenance mode on a vCenter host, both vCenter and CloudStack
must be used in concert. CloudStack and vCenter have separate
maintenance modes that work closely together.</p>
<ol class="arabic">
<li><p class="first">Place the host into CloudStack’s “scheduled maintenance” mode. This
does not invoke the vCenter maintenance mode, but only causes VMs to
be migrated off the host</p>
<p>When the CloudStack maintenance mode is requested, the host first
moves into the Prepare for Maintenance state. In this state it cannot
be the target of new guest VM starts. Then all VMs will be migrated
off the server. Live migration will be used to move VMs off the host.
This allows the guests to be migrated to other hosts with no
disruption to the guests. After this migration is completed, the host
will enter the Ready for Maintenance mode.</p>
</li>
<li><p class="first">Wait for the “Ready for Maintenance” indicator to appear in the UI.</p>
</li>
<li><p class="first">Now use vCenter to perform whatever actions are necessary to maintain
the host. During this time, the host cannot be the target of new VM
allocations.</p>
</li>
<li><p class="first">When the maintenance tasks are complete, take the host out of
maintenance mode as follows:</p>
<ol class="arabic">
<li><p class="first">First use vCenter to exit the vCenter maintenance mode.</p>
<p>This makes the host ready for CloudStack to reactivate it.</p>
</li>
<li><p class="first">Then use CloudStack’s administrator UI to cancel the CloudStack
maintenance mode</p>
<p>When the host comes back online, the VMs that were migrated off of
it may be migrated back to it manually and new VMs can be added.</p>
</li>
</ol>
</li>
</ol>
</div>
<div class="section" id="xenserver-and-maintenance-mode">
<h2>XenServer and Maintenance Mode<a class="headerlink" href="hosts.html#xenserver-and-maintenance-mode" title="Permalink to this headline">¶</a></h2>
<p>For XenServer, you can take a server offline temporarily by using the
Maintenance Mode feature in XenCenter. When you place a server into
Maintenance Mode, all running VMs are automatically migrated from it to
another host in the same pool. If the server is the pool master, a new
master will also be selected for the pool. While a server is Maintenance
Mode, you cannot create or start any VMs on it.</p>
<p><strong>To place a server in Maintenance Mode:</strong></p>
<ol class="arabic simple">
<li>In the Resources pane, select the server, then do one of the
following:<ul>
<li>Right-click, then click Enter Maintenance Mode on the shortcut
menu.</li>
<li>On the Server menu, click Enter Maintenance Mode.</li>
</ul>
</li>
<li>Click Enter Maintenance Mode.</li>
</ol>
<p>The server’s status in the Resources pane shows when all running VMs
have been successfully migrated off the server.</p>
<p><strong>To take a server out of Maintenance Mode:</strong></p>
<ol class="arabic simple">
<li>In the Resources pane, select the server, then do one of the
following:<ul>
<li>Right-click, then click Exit Maintenance Mode on the shortcut
menu.</li>
<li>On the Server menu, click Exit Maintenance Mode.</li>
</ul>
</li>
<li>Click Exit Maintenance Mode.</li>
</ol>
</div>
</div>
<div class="section" id="disabling-and-enabling-zones-pods-and-clusters">
<h1>资源域、池和集群的启用和禁用<a class="headerlink" href="hosts.html#disabling-and-enabling-zones-pods-and-clusters" title="Permalink to this headline">¶</a></h1>
<p>You can enable or disable a zone, pod, or cluster without permanently
removing it from the cloud. This is useful for maintenance or when there
are problems that make a portion of the cloud infrastructure unreliable.
No new allocations will be made to a disabled zone, pod, or cluster
until its state is returned to Enabled. When a zone, pod, or cluster is
first added to the cloud, it is Disabled by default.</p>
<p>To disable and enable a zone, pod, or cluster:</p>
<ol class="arabic simple">
<li>Log in to the CloudStack UI as administrator</li>
<li>In the left navigation bar, click Infrastructure.</li>
<li>In Zones, click View More.</li>
<li>If you are disabling or enabling a zone, find the name of the zone in
the list, and click the Enable/Disable button. <img alt="button to enable or disable zone, pod, or cluster." src="../images/enable-disable.png" /></li>
<li>If you are disabling or enabling a pod or cluster, click the name of
the zone that contains the pod or cluster.</li>
<li>Click the Compute tab.</li>
<li>In the Pods or Clusters node of the diagram, click View All.</li>
<li>Click the pod or cluster name in the list.</li>
<li>Click the Enable/Disable button. <img alt="button to enable or disable zone, pod, or cluster." src="../images/enable-disable.png" /></li>
</ol>
</div>
<div class="section" id="removing-hosts">
<h1>删除主机<a class="headerlink" href="hosts.html#removing-hosts" title="Permalink to this headline">¶</a></h1>
<p>Hosts can be removed from the cloud as needed. The procedure to remove a
host depends on the hypervisor type.</p>
<div class="section" id="removing-xenserver-and-kvm-hosts">
<h2>Removing XenServer and KVM Hosts<a class="headerlink" href="hosts.html#removing-xenserver-and-kvm-hosts" title="Permalink to this headline">¶</a></h2>
<p>A node cannot be removed from a cluster until it has been placed in
maintenance mode. This will ensure that all of the VMs on it have been
migrated to other Hosts. To remove a Host from the cloud:</p>
<ol class="arabic">
<li><p class="first">Place the node in maintenance mode.</p>
<p>See <a class="reference external" href="hosts.html#scheduled-maintenance-and-maintenance-mode-for-hosts">“Scheduled Maintenance and Maintenance Mode for
Hosts”</a>.</p>
</li>
<li><p class="first">For KVM, stop the cloud-agent service.</p>
</li>
<li><p class="first">Use the UI option to remove the node.</p>
<p>Then you may power down the Host, re-use its IP address, re-install
it, etc</p>
</li>
</ol>
</div>
<div class="section" id="removing-vsphere-hosts">
<h2>Removing vSphere Hosts<a class="headerlink" href="hosts.html#removing-vsphere-hosts" title="Permalink to this headline">¶</a></h2>
<p>To remove this type of host, first place it in maintenance mode, as
described in <a class="reference external" href="hosts.html#scheduled-maintenance-and-maintenance-mode-for-hosts">“Scheduled Maintenance and Maintenance Mode
for Hosts”</a>. Then use
CloudStack to remove the host. CloudStack will not direct commands to a
host that has been removed using CloudStack. However, the host may still
exist in the vCenter cluster.</p>
</div>
</div>
<div class="section" id="re-installing-hosts">
<h1>Re-Installing Hosts<a class="headerlink" href="hosts.html#re-installing-hosts" title="Permalink to this headline">¶</a></h1>
<p>You can re-install a host after placing it in maintenance mode and then
removing it. If a host is down and cannot be placed in maintenance mode,
it should still be removed before the re-install.</p>
</div>
<div class="section" id="maintaining-hypervisors-on-hosts">
<h1>Maintaining Hypervisors on Hosts<a class="headerlink" href="hosts.html#maintaining-hypervisors-on-hosts" title="Permalink to this headline">¶</a></h1>
<p>When running hypervisor software on hosts, be sure all the hotfixes
provided by the hypervisor vendor are applied. Track the release of
hypervisor patches through your hypervisor vendor’s support channel, and
apply patches as soon as possible after they are released. CloudStack
will not track or notify you of required hypervisor patches. It is
essential that your hosts are completely up to date with the provided
hypervisor patches. The hypervisor vendor is likely to refuse to support
any system that is not up to date with patches.</p>
<div class="admonition note">
<p class="first admonition-title">提示</p>
<p class="last">The lack of up-do-date hotfixes can lead to data corruption and lost VMs.</p>
</div>
<p>(XenServer) For more information, see
<a class="reference external" href="http://docs.cloudstack.org/Knowledge_Base/Possible_VM_corruption_if_XenServer_Hotfix_is_not_Applied/Highly_Recommended_Hotfixes_for_XenServer_5.6_SP2">Highly Recommended Hotfixes for XenServer in the CloudStack Knowledge Base</a>.</p>
</div>
<div class="section" id="changing-host-password">
<h1>修改主机密码<a class="headerlink" href="hosts.html#changing-host-password" title="Permalink to this headline">¶</a></h1>
<p>The password for a XenServer Node, KVM Node, or vSphere Node may be
changed in the database. Note that all Nodes in a 集群 must have the
same password.</p>
<p>To change a Node’s password:</p>
<ol class="arabic">
<li><p class="first">Identify all hosts in the cluster.</p>
</li>
<li><p class="first">Change the password on all hosts in the cluster. Now the password for
the host and the password known to CloudStack will not match.
Operations on the cluster will fail until the two passwords match.</p>
</li>
<li><p class="first">if the password in the database is encrypted, it is (likely) necessary to
encrypt the new password using the database key before adding it to the database.</p>
<div class="code bash highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">java</span> <span class="o">-</span><span class="n">classpath</span> <span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">share</span><span class="o">/</span><span class="n">cloudstack</span><span class="o">-</span><span class="n">common</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">jasypt</span><span class="o">-</span><span class="mf">1.9</span><span class="o">.</span><span class="mf">0.</span><span class="n">jar</span> \
<span class="n">org</span><span class="o">.</span><span class="n">jasypt</span><span class="o">.</span><span class="n">intf</span><span class="o">.</span><span class="n">cli</span><span class="o">.</span><span class="n">JasyptPBEStringEncryptionCLI</span> \
<span class="n">encrypt</span><span class="o">.</span><span class="n">sh</span> <span class="nb">input</span><span class="o">=</span><span class="s2">&quot;newrootpassword&quot;</span> \
<span class="n">password</span><span class="o">=</span><span class="s2">&quot;databasekey&quot;</span> \
<span class="n">verbose</span><span class="o">=</span><span class="n">false</span>
</pre></div>
</div>
</li>
<li><p class="first">Get the list of host IDs for the host in the cluster where you are
changing the password. You will need to access the database to
determine these host IDs. For each hostname “h” (or vSphere cluster)
that you are changing the password for, execute:</p>
<div class="code bash highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mysql</span><span class="o">&gt;</span> <span class="n">SELECT</span> <span class="nb">id</span> <span class="n">FROM</span> <span class="n">cloud</span><span class="o">.</span><span class="n">host</span> <span class="n">WHERE</span> <span class="n">name</span> <span class="n">like</span> <span class="s1">&#39;</span><span class="si">%h%</span><span class="s1">&#39;</span><span class="p">;</span>
</pre></div>
</div>
</li>
<li><p class="first">This should return a single ID. Record the set of such IDs for these
hosts. Now retrieve the host_details row id for the host</p>
<div class="code bash highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mysql</span><span class="o">&gt;</span> <span class="n">SELECT</span> <span class="o">*</span> <span class="n">FROM</span> <span class="n">cloud</span><span class="o">.</span><span class="n">host_details</span> <span class="n">WHERE</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;password&#39;</span> <span class="n">AND</span> <span class="n">host_id</span><span class="o">=</span><span class="p">{</span><span class="n">previous</span> <span class="n">step</span> <span class="n">ID</span><span class="p">};</span>
</pre></div>
</div>
</li>
<li><p class="first">Update the passwords for the host in the database. In this example,
we change the passwords for hosts with host IDs 5 and 12 and host_details IDs 8 and 22 to
“password”.</p>
<div class="code bash highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mysql</span><span class="o">&gt;</span> <span class="n">UPDATE</span> <span class="n">cloud</span><span class="o">.</span><span class="n">host_details</span> <span class="n">SET</span> <span class="n">value</span><span class="o">=</span><span class="s1">&#39;password&#39;</span> <span class="n">WHERE</span> <span class="nb">id</span><span class="o">=</span><span class="mi">8</span> <span class="n">OR</span> <span class="nb">id</span><span class="o">=</span><span class="mi">22</span><span class="p">;</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="over-provisioning-and-service-offering-limits">
<h1>Over-Provisioning and Service Offering Limits<a class="headerlink" href="hosts.html#over-provisioning-and-service-offering-limits" title="Permalink to this headline">¶</a></h1>
<p>(Supported for XenServer, KVM, and VMware)</p>
<p>CPU and memory (RAM) over-provisioning factors can be set for each
cluster to change the number of VMs that can run on each host in the
cluster. This helps optimize the use of resources. By increasing the
over-provisioning ratio, more resource capacity will be used. If the
ratio is set to 1, no over-provisioning is done.</p>
<p>The administrator can also set global default over-provisioning ratios
in the cpu.overprovisioning.factor and mem.overprovisioning.factor
global configuration variables. The default value of these variables is
1: over-provisioning is turned off by default.</p>
<p>Over-provisioning ratios are dynamically substituted in CloudStack’s
capacity calculations. For example:</p>
<p>Capacity = 2 GB
Over-provisioning factor = 2
Capacity after over-provisioning = 4 GB</p>
<p>With this configuration, suppose you deploy 3 VMs of 1 GB each:</p>
<p>Used = 3 GB
Free = 1 GB</p>
<p>The administrator can specify a memory over-provisioning ratio, and can
specify both CPU and memory over-provisioning ratios on a per-cluster
basis.</p>
<p>In any given cloud, the optimum number of VMs for each host is affected
by such things as the hypervisor, storage, and hardware configuration.
These may be different for each cluster in the same cloud. A single
global over-provisioning setting can not provide the best utilization
for all the different clusters in the cloud. It has to be set for the
lowest common denominator. The per-cluster setting provides a finer
granularity for better utilization of resources, no matter where the
CloudStack placement algorithm decides to place a VM.</p>
<p>The overprovisioning settings can be used along with dedicated resources
(assigning a specific cluster to an account) to effectively offer
different levels of service to different accounts. For example, an
account paying for a more expensive level of service could be assigned
to a dedicated cluster with an over-provisioning ratio of 1, and a
lower-paying account to a cluster with a ratio of 2.</p>
<p>When a new host is added to a cluster, CloudStack will assume the host
has the capability to perform the CPU and RAM over-provisioning which is
configured for that cluster. It is up to the administrator to be sure
the host is actually suitable for the level of over-provisioning which
has been set.</p>
<div class="section" id="limitations-on-over-provisioning-in-xenserver-and-kvm">
<h2>Limitations on Over-Provisioning in XenServer and KVM<a class="headerlink" href="hosts.html#limitations-on-over-provisioning-in-xenserver-and-kvm" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>In XenServer, due to a constraint of this hypervisor, you can not use
an over-provisioning factor greater than 4.</li>
<li>The KVM hypervisor can not manage memory allocation to VMs
dynamically. CloudStack sets the minimum and maximum amount of memory
that a VM can use. The hypervisor adjusts the memory within the set
limits based on the memory contention.</li>
</ul>
</div>
<div class="section" id="requirements-for-over-provisioning">
<h2>Requirements for Over-Provisioning<a class="headerlink" href="hosts.html#requirements-for-over-provisioning" title="Permalink to this headline">¶</a></h2>
<p>Several prerequisites are required in order for over-provisioning to
function properly. The feature is dependent on the OS type, hypervisor
capabilities, and certain scripts. It is the administrator’s
responsibility to ensure that these requirements are met.</p>
<div class="section" id="balloon-driver">
<h3>Balloon Driver<a class="headerlink" href="hosts.html#balloon-driver" title="Permalink to this headline">¶</a></h3>
<p>All VMs should have a balloon driver installed in them. The hypervisor
communicates with the balloon driver to free up and make the memory
available to a VM.</p>
<div class="section" id="xenserver">
<h4>XenServer<a class="headerlink" href="hosts.html#xenserver" title="Permalink to this headline">¶</a></h4>
<p>The balloon driver can be found as a part of xen pv or PVHVM drivers.
The xen pvhvm drivers are included in upstream linux kernels 2.6.36+.</p>
</div>
<div class="section" id="vmware">
<h4>VMware<a class="headerlink" href="hosts.html#vmware" title="Permalink to this headline">¶</a></h4>
<p>The balloon driver can be found as a part of the VMware tools. All the
VMs that are deployed in a over-provisioned cluster should have the
VMware tools installed.</p>
</div>
<div class="section" id="kvm">
<h4>KVM<a class="headerlink" href="hosts.html#kvm" title="Permalink to this headline">¶</a></h4>
<p>All VMs are required to support the virtio drivers. These drivers are
installed in all Linux kernel versions 2.6.25 and greater. The
administrator must set CONFIG_VIRTIO_BALLOON=y in the virtio
configuration.</p>
</div>
</div>
<div class="section" id="hypervisor-capabilities">
<h3>Hypervisor capabilities<a class="headerlink" href="hosts.html#hypervisor-capabilities" title="Permalink to this headline">¶</a></h3>
<p>The hypervisor must be capable of using the memory ballooning.</p>
<div class="section" id="id3">
<h4>XenServer<a class="headerlink" href="hosts.html#id3" title="Permalink to this headline">¶</a></h4>
<p>The DMC (Dynamic Memory Control) capability of the hypervisor should be
enabled. Only XenServer Advanced and above versions have this feature.</p>
</div>
<div class="section" id="vmware-kvm">
<h4>VMware, KVM<a class="headerlink" href="hosts.html#vmware-kvm" title="Permalink to this headline">¶</a></h4>
<p>Memory ballooning is supported by default.</p>
</div>
</div>
</div>
<div class="section" id="setting-over-provisioning-ratios">
<h2>Setting Over-Provisioning Ratios<a class="headerlink" href="hosts.html#setting-over-provisioning-ratios" title="Permalink to this headline">¶</a></h2>
<p>There are two ways the root admin can set CPU and RAM over-provisioning
ratios. First, the global configuration settings
cpu.overprovisioning.factor and mem.overprovisioning.factor will be
applied when a new cluster is created. Later, the ratios can be modified
for an existing cluster.</p>
<p>Only VMs deployed after the change are affected by the new setting. If
you want VMs deployed before the change to adopt the new
over-provisioning ratio, you must stop and restart the VMs. When this is
done, CloudStack recalculates or scales the used and reserved capacities
based on the new over-provisioning ratios, to ensure that CloudStack is
correctly tracking the amount of free capacity.</p>
<div class="admonition note">
<p class="first admonition-title">提示</p>
<p class="last">It is safer not to deploy additional new VMs while the capacity
recalculation is underway, in case the new values for available
capacity are not high enough to accommodate the new VMs. Just wait
for the new used/available values to become available, to be sure
there is room for all the new VMs you want.</p>
</div>
<p>To change the over-provisioning ratios for an existing cluster:</p>
<ol class="arabic">
<li><p class="first">Log in as administrator to the CloudStack UI.</p>
</li>
<li><p class="first">In the left navigation bar, click Infrastructure.</p>
</li>
<li><p class="first">Under Clusters, click View All.</p>
</li>
<li><p class="first">Select the cluster you want to work with, and click the Edit button.</p>
</li>
<li><p class="first">Fill in your desired over-provisioning multipliers in the fields CPU
overcommit ratio and RAM overcommit ratio. The value which is
intially shown in these fields is the default value inherited from
the global configuration settings.</p>
<div class="admonition note">
<p class="first admonition-title">提示</p>
<p class="last">In XenServer, due to a constraint of this hypervisor, you can not
use an over-provisioning factor greater than 4.</p>
</div>
</li>
</ol>
</div>
<div class="section" id="service-offering-limits-and-over-provisioning">
<h2>Service Offering Limits and Over-Provisioning<a class="headerlink" href="hosts.html#service-offering-limits-and-over-provisioning" title="Permalink to this headline">¶</a></h2>
<p>Service offering limits (e.g. 1 GHz, 1 core) are strictly enforced for
core count. For example, a guest with a service offering of one core
will have only one core available to it regardless of other activity on
the Host.</p>
<p>Service offering limits for gigahertz are enforced only in the presence
of contention for CPU resources. For example, suppose that a guest was
created with a service offering of 1 GHz on a Host that has 2 GHz cores,
and that guest is the only guest running on the Host. The guest will
have the full 2 GHz available to it. When multiple guests are attempting
to use the CPU a weighting factor is used to schedule CPU resources. The
weight is based on the clock speed in the service offering. Guests
receive a CPU allocation that is proportionate to the GHz in the service
offering. For example, a guest created from a 2 GHz service offering
will receive twice the CPU allocation as a guest created from a 1 GHz
service offering. CloudStack does not perform memory over-provisioning.</p>
</div>
</div>
<div class="section" id="vlan-provisioning">
<h1>VLAN Provisioning<a class="headerlink" href="hosts.html#vlan-provisioning" title="Permalink to this headline">¶</a></h1>
<p>CloudStack automatically creates and destroys interfaces bridged to
VLANs on the hosts. In general the administrator does not need to manage
this process.</p>
<p>CloudStack manages VLANs differently based on hypervisor type. For
XenServer or KVM, the VLANs are created on only the hosts where they
will be used and then they are destroyed when all guests that require
them have been terminated or moved to another host.</p>
<p>For vSphere the VLANs are provisioned on all hosts in the cluster even
if there is no guest running on a particular Host that requires the
VLAN. This allows the administrator to perform live migration and other
functions in vCenter without having to create the VLAN on the
destination Host. Additionally, the VLANs are not removed from the Hosts
when they are no longer needed.</p>
<p>You can use the same VLANs on different physical networks provided that
each physical network has its own underlying layer-2 infrastructure,
such as switches. For example, you can specify VLAN range 500 to 1000
while deploying physical networks A and B in an Advanced zone setup.
This capability allows you to set up an additional layer-2 physical
infrastructure on a different physical NIC and use the same set of VLANs
if you run out of VLANs. Another advantage is that you can use the same
set of IPs for different customers, each one with their own routers and
the guest networks on different physical NICs.</p>
<div class="section" id="vlan-allocation-example">
<h2>VLAN 划分示例<a class="headerlink" href="hosts.html#vlan-allocation-example" title="Permalink to this headline">¶</a></h2>
<p>VLANs are required for public and guest traffic. The following is an
example of a VLAN allocation scheme:</p>
<table border="1" class="table-striped table-bordered table-hover docutils">
<colgroup>
<col width="12%" />
<col width="20%" />
<col width="68%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">VLAN IDs</th>
<th class="head">Traffic type</th>
<th class="head">Scope</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>less than 500</td>
<td>Management traffic.</td>
<td>Reserved for administrative purposes.  CloudStack software can access this, hypervisors, system VMs.</td>
</tr>
<tr class="row-odd"><td>500-599</td>
<td>VLAN carrying public traffic.</td>
<td>CloudStack accounts.</td>
</tr>
<tr class="row-even"><td>600-799</td>
<td>VLANs carrying guest traffic.</td>
<td>CloudStack accounts. Account-specific VLAN is chosen from this pool.</td>
</tr>
<tr class="row-odd"><td>800-899</td>
<td>VLANs carrying guest traffic.</td>
<td>CloudStack accounts. Account-specific VLAN chosen by CloudStack admin to assign to that account.</td>
</tr>
<tr class="row-even"><td>900-999</td>
<td>VLAN carrying guest traffic</td>
<td>CloudStack accounts. Can be scoped by project, domain, or all accounts.</td>
</tr>
<tr class="row-odd"><td>greater than 1000</td>
<td>Reserved for future use</td>
<td>&#160;</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="adding-non-contiguous-vlan-ranges">
<h2>Adding Non Contiguous VLAN Ranges<a class="headerlink" href="hosts.html#adding-non-contiguous-vlan-ranges" title="Permalink to this headline">¶</a></h2>
<p>CloudStack provides you with the flexibility to add non contiguous VLAN
ranges to your network. The administrator can either update an existing
VLAN range or add multiple non contiguous VLAN ranges while creating a
zone. You can also use the UpdatephysicalNetwork API to extend the VLAN
range.</p>
<ol class="arabic">
<li><p class="first">Log in to the CloudStack UI as an administrator or end user.</p>
</li>
<li><p class="first">Ensure that the VLAN range does not already exist.</p>
</li>
<li><p class="first">In the left navigation, choose Infrastructure.</p>
</li>
<li><p class="first">On Zones, click View More, then click the zone to which you want to
work with.</p>
</li>
<li><p class="first">Click Physical Network.</p>
</li>
<li><p class="first">In the Guest node of the diagram, click Configure.</p>
</li>
<li><p class="first">Click Edit <img alt="button to edit the VLAN range." src="../images/edit-icon.png" />.</p>
<p>The VLAN Ranges field now is editable.</p>
</li>
<li><p class="first">Specify the start and end of the VLAN range in comma-separated list.</p>
<p>Specify all the VLANs you want to use, VLANs not specified will be
removed if you are adding new ranges to the existing list.</p>
</li>
<li><p class="first">Click Apply.</p>
</li>
</ol>
</div>
<div class="section" id="assigning-vlans-to-isolated-networks">
<h2>Assigning VLANs to Isolated Networks<a class="headerlink" href="hosts.html#assigning-vlans-to-isolated-networks" title="Permalink to this headline">¶</a></h2>
<p>CloudStack provides you the ability to control VLAN assignment to
Isolated networks. As a Root admin, you can assign a VLAN ID when a
network is created, just the way it’s done for Shared networks.</p>
<p>The former behaviour also is supported — VLAN is randomly allocated to a
network from the VNET range of the physical network when the network
turns to Implemented state. The VLAN is released back to the VNET pool
when the network shuts down as a part of the Network Garbage Collection.
The VLAN can be re-used either by the same network when it is
implemented again, or by any other network. On each subsequent
implementation of a network, a new VLAN can be assigned.</p>
<p>Only the Root admin can assign VLANs because the regular users or domain
admin are not aware of the physical network topology. They cannot even
view what VLAN is assigned to a network.</p>
<p>To enable you to assign VLANs to Isolated networks,</p>
<ol class="arabic">
<li><p class="first">Create a network offering by specifying the following:</p>
<ul class="simple">
<li><strong>Guest Type</strong>: Select Isolated.</li>
<li><strong>Specify VLAN</strong>: Select the option.</li>
</ul>
<p>For more information, see the CloudStack 安装指南.</p>
</li>
<li><p class="first">Using this network offering, create a network.</p>
<p>You can create a VPC tier or an Isolated network.</p>
</li>
<li><p class="first">Specify the VLAN when you create the network.</p>
<p>When VLAN is specified, a CIDR and gateway are assigned to this
network and the state is changed to Setup. In this state, the network
will not be garbage collected.</p>
</li>
</ol>
<div class="admonition note">
<p class="first admonition-title">提示</p>
<p class="last">You cannot change a VLAN once it’s assigned to the network. The VLAN
remains with the network for its entire life cycle.</p>
</div>
</div>
</div>
<div class="section" id="out-of-band-management">
<h1>Out-of-band Management<a class="headerlink" href="hosts.html#out-of-band-management" title="Permalink to this headline">¶</a></h1>
<p>CloudStack provides Root admins the ability to configure and use supported
out-of-band management interface (e.g. IPMI, iLO, DRAC, etc.) on a physical
host to manage host power operations such as on, off, reset etc. By default,
IPMI 2.0 baseboard controller are supported out of the box with <code class="docutils literal notranslate"><span class="pre">IPMITOOL</span></code>
out-of-band management driver in CloudStack that uses <code class="docutils literal notranslate"><span class="pre">ipmitool</span></code> for performing
IPMI 2.0 management operations.</p>
<p>Following are some global settings that control various aspects of this feature.</p>
<table border="1" class="table-striped table-bordered table-hover docutils">
<colgroup>
<col width="23%" />
<col width="17%" />
<col width="60%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Global setting</th>
<th class="head">Default values</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>outofbandmanagement.action.timeout</td>
<td>60</td>
<td>The out of band management action timeout in seconds, configurable per cluster</td>
</tr>
<tr class="row-odd"><td>outofbandmanagement.ipmitool.interface</td>
<td>lanplus</td>
<td>The out of band management IpmiTool driver interface to use. Valid values are: lan, lanplus etc</td>
</tr>
<tr class="row-even"><td>outofbandmanagement.ipmitool.path</td>
<td>/usr/bin/ipmitool</td>
<td>The out of band management ipmitool path used by the IpmiTool driver</td>
</tr>
<tr class="row-odd"><td>outofbandmanagement.ipmitool.retries</td>
<td>1</td>
<td>The out of band management IpmiTool driver retries option -R</td>
</tr>
<tr class="row-even"><td>outofbandmanagement.sync.poolsize</td>
<td>50</td>
<td>The out of band management background sync thread pool size 50</td>
</tr>
</tbody>
</table>
<p>A change in <code class="docutils literal notranslate"><span class="pre">outofbandmanagement.sync.poolsize</span></code> settings requires restarting of
management server(s) as the thread pool and a background (power state) sync
thread are configured during load time when CloudStack management server starts.
Rest of the global settings can be changed without requiring restarting of
management server(s).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">outofbandmanagement.sync.poolsize</span></code> is the maximum number of ipmitool
background power state scanners that can run at a time. Based on the maximum
number of hosts you’ve, you can increase/decrease the value depending on how much
stress your management server host can endure. It will take atmost number of
total out-of-band-management enabled hosts in a round *
<code class="docutils literal notranslate"><span class="pre">outofbandmanagement.action.timeout</span></code> / <code class="docutils literal notranslate"><span class="pre">outofbandmanagement.sync.poolsize</span></code> seconds
to complete a background power-state sync scan in a single round.</p>
<p>In order to use this feature, the Root admin needs to first configure
out-of-band management for a host using either the UI or the
<code class="docutils literal notranslate"><span class="pre">configureOutOfBandManagement</span></code> API. Next, the Root admin needs to enable it.
The feature can be enabled or disabled across a zone or a cluster or a host,</p>
<p>Once out-of-band management is configured and enabled for a host (and provided
not disabled at zone or cluster level), Root admins would be able to issue
power management actions such as on, off, reset, cycle, soft and status.</p>
<p>If a host is in maintenance mode, Root admins are still allowed to perform
power management actions but in the UI a 警告 is displayed.</p>
</div>
<div class="section" id="security">
<span id="host-security"></span><h1>安全<a class="headerlink" href="hosts.html#security" title="Permalink to this headline">¶</a></h1>
<p>Starting 4.11, CloudStack has an inbuilt certicate authority (CA) framework and
a default ‘root’ CA provider which acts as a self-signed CA. The CA framework
participates in certificate issuance, renewal, revocation, and propagation of
certificates during setup of a host. This framework is primary used to
secure communications between CloudStack management server(s), the
KVM/LXC/SSVM/CPVM agent(s) and peer management server(s).</p>
<p>Following are some global settings that control various aspects of this feature.</p>
<table border="1" class="table-striped table-bordered table-hover docutils">
<colgroup>
<col width="36%" />
<col width="64%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Global setting</th>
<th class="head">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>ca.framework.provider.plugin</td>
<td>The configured CA provider plugin</td>
</tr>
<tr class="row-odd"><td>ca.framework.cert.keysize</td>
<td>The key size used for certificate generation</td>
</tr>
<tr class="row-even"><td>ca.framework.cert.signature.algorithm</td>
<td>The certificate signature algorithm</td>
</tr>
<tr class="row-odd"><td>ca.framework.cert.validity.period</td>
<td>Certificate validity in days</td>
</tr>
<tr class="row-even"><td>ca.framework.cert.automatic.renewal</td>
<td>Whether to auto-renew expiring certificate on hosts</td>
</tr>
<tr class="row-odd"><td>ca.framework.background.task.delay</td>
<td>The delay between each CA background task round in seconds</td>
</tr>
<tr class="row-even"><td>ca.framework.cert.expiry.alert.period</td>
<td>The number of days to check and alert expiring certificates</td>
</tr>
<tr class="row-odd"><td>ca.plugin.root.private.key</td>
<td>(hidden/encrypted in database) Auto-generated CA private key</td>
</tr>
<tr class="row-even"><td>ca.plugin.root.public.key</td>
<td>(hidden/encrypted in database) CA public key</td>
</tr>
<tr class="row-odd"><td>ca.plugin.root.ca.certificate</td>
<td>(hidden/encrypted in database) CA certificate</td>
</tr>
<tr class="row-even"><td>ca.plugin.root.issuer.dn</td>
<td>The CA issue distinguished name used by the root CA provider</td>
</tr>
<tr class="row-odd"><td>ca.plugin.root.auth.strictness</td>
<td>Setting to enforce two-way SSL authentication and trust validation</td>
</tr>
<tr class="row-even"><td>ca.plugin.root.allow.expired.cert</td>
<td>Setting to allow clients with expired certificates</td>
</tr>
</tbody>
</table>
<p>A change in <code class="docutils literal notranslate"><span class="pre">ca.framework.background.task.delay</span></code> settings requires restarting of
management server(s) as the thread pool and a background tasks are configured
only when CloudStack management server(s) start.</p>
<p>After upgrade to CloudStack 4.11+, the CA framework will by default use the
<code class="docutils literal notranslate"><span class="pre">root</span></code> CA provider. This CA provider will auto-generate its private/public keys
and CA certificate on first boot post-upgrade. For freshly installed
environments, the <code class="docutils literal notranslate"><span class="pre">ca.plugin.root.auth.strictness</span></code> setting will be <code class="docutils literal notranslate"><span class="pre">true</span></code> to
enforce two-way SSL authentication and trust validation between client and
server components, however, it will be <code class="docutils literal notranslate"><span class="pre">false</span></code> on upgraded environments to
be backward compatible with legacy behaviour of trusting all clients and
servers, and one-way SSL authentication. Upgraded/existing environments can
use the <code class="docutils literal notranslate"><span class="pre">provisionCertificate</span></code> API to renew/setup certificates for already
connected agents/hosts, and once all the agents/hosts are secured they may
enforce authentication and validation strictness by setting
<code class="docutils literal notranslate"><span class="pre">ca.plugin.root.auth.strictness</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code> and restarting the management
server(s).</p>
</div>
<div class="section" id="server-address-usage">
<h1>Server Address Usage<a class="headerlink" href="hosts.html#server-address-usage" title="Permalink to this headline">¶</a></h1>
<p>Historically, when multiple management servers are used a tcp-LB is used on
port 8250 (default) of the management servers and the VIP/LB-IP is used as the
<code class="docutils literal notranslate"><span class="pre">host</span></code> setting to be used by various CloudStack agents such as the KVM, CPVM,
SSVM agents, who connect to the <code class="docutils literal notranslate"><span class="pre">host</span></code> on port 8250. However, starting
CloudStack 4.11+ the <code class="docutils literal notranslate"><span class="pre">host</span></code> setting can accept comma separated list of
management server IPs to which new CloudStack hosts/agents will get a shuffled
list of the same to which they can cycle reconnections in a round-robin way.</p>
</div>
<div class="section" id="securing-process">
<h1>Securing Process<a class="headerlink" href="hosts.html#securing-process" title="Permalink to this headline">¶</a></h1>
<p>Agents while making connections/reconnections to management server will only
validate server certificate and be able to present client certificate (issued to
them) when <code class="docutils literal notranslate"><span class="pre">cloud.jks</span></code> is accessible to them. On older hosts that are setup
prior to this feature the keystore won’t be available, however, they can still
connect to management server(s) if <code class="docutils literal notranslate"><span class="pre">ca.plugin.root.auth.strictness</span></code> is set to
<code class="docutils literal notranslate"><span class="pre">false</span></code>. Management server(s) will check and setup their own <code class="docutils literal notranslate"><span class="pre">cloud.jks</span></code>
keystore on startup, this keystore will be used for connecting to peer
management server(s).</p>
<p>When a new host is being setup, such as adding a KVM host or starting a systemvm
host, the CA framework kicks in and uses ssh to execute <code class="docutils literal notranslate"><span class="pre">keystore-setup</span></code> to
generate a new keystore file <code class="docutils literal notranslate"><span class="pre">cloud.jks.new</span></code>, save a random passphrase of the
keystore in the agent’s properties file and a CSR <code class="docutils literal notranslate"><span class="pre">cloud.csr</span></code> file. The CSR is
then used to issue certificate for that agent/host and ssh is used to execute
<code class="docutils literal notranslate"><span class="pre">keystore-cert-import</span></code> to import the issued certificate along with the CA
certificate(s), the keystore is that renamed as <code class="docutils literal notranslate"><span class="pre">cloud.jks</span></code> replacing an
previous keystore in-use. During this process, keys and certificates files are
also stored in <code class="docutils literal notranslate"><span class="pre">cloud.key</span></code>, <code class="docutils literal notranslate"><span class="pre">cloud.crt</span></code>, <code class="docutils literal notranslate"><span class="pre">cloud.ca.crt</span></code> in the
agent’s configuration directory.</p>
<p>When hosts are added out-of-band, for example a KVM host that is setup first
outside of CloudStack and added to a cluster, the keystore file will not be
available however the keystore and security could be setup by using keystore
utility scripts manually. The <code class="docutils literal notranslate"><span class="pre">keystore-setup</span></code> can be ran first to generate a
keystore and a CSR, then CloudStack CA can be used to issue certificate by
providing the CSR to the <code class="docutils literal notranslate"><span class="pre">issueCertificate</span></code> API, and finally issued certificate
and CA certificate(s) can be imported to the keystore using <code class="docutils literal notranslate"><span class="pre">keystore-cert-import</span></code>
script.</p>
<p>Following lists the usage of these scripts, when using these script use full
paths, use the final keystore filename as <code class="docutils literal notranslate"><span class="pre">cloud.jks</span></code>, and the certificate/key
content need to be encoded and provided such that newlines are replace with <code class="docutils literal notranslate"><span class="pre">^</span></code>
and space are replaced with <code class="docutils literal notranslate"><span class="pre">~</span></code>:</p>
<div class="code bash highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">keystore</span><span class="o">-</span><span class="n">setup</span> <span class="o">&lt;</span><span class="n">properties</span> <span class="n">file</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">keystore</span> <span class="n">file</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">passphrase</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">validity</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">csr</span> <span class="n">file</span><span class="o">&gt;</span>

<span class="n">keystore</span><span class="o">-</span><span class="n">cert</span><span class="o">-</span><span class="kn">import</span> <span class="o">&lt;</span><span class="n">properties</span> <span class="n">file</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">keystore</span> <span class="n">file</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">mode</span><span class="p">:</span> <span class="n">ssh</span><span class="o">|</span><span class="n">agent</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">cert</span> <span class="n">file</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">cert</span> <span class="n">content</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">ca</span><span class="o">-</span><span class="n">cert</span> <span class="n">file</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">ca</span><span class="o">-</span><span class="n">cert</span> <span class="n">content</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">private</span><span class="o">-</span><span class="n">key</span> <span class="n">file</span><span class="o">&gt;</span> <span class="o">&lt;</span><span class="n">private</span> <span class="n">key</span> <span class="n">content</span><span class="p">:</span><span class="n">optional</span><span class="o">&gt;</span>
</pre></div>
</div>
<p>Starting 4.11.1, a KVM host is considered secured when it has its keystore and
certificates setup for both the agent and libvirtd process. A secured host will
only allow and initiate TLS enabled live VM migration. This requires libvirtd
to listen on default port 16514, and the port to be allowed in the firewall
rules. Certificate renewal (using the <code class="docutils literal notranslate"><span class="pre">provisionCertificate</span></code> API) will restart
both the libvirtd process and agent after deploying new certificates.</p>
</div>
<div class="section" id="kvm-libvirt-hook-script-include">
<h1>KVM Libvirt Hook Script Include<a class="headerlink" href="hosts.html#kvm-libvirt-hook-script-include" title="Permalink to this headline">¶</a></h1>
<div class="section" id="feature-overview">
<h2>Feature 概述<a class="headerlink" href="hosts.html#feature-overview" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>This feature applies to KVM hosts.</li>
<li>KVM utilised under CloudStack uses the standard Libvirt hook script behaviour as outlined in the Libvirt documentation page <a class="reference external" href="https://libvirt.org/hooks.html">hooks</a>.</li>
<li>During the install of the KVM CloudStack agent, the Libvirt hook script “/etc/libvirt/hooks/qemu”, referred to as the qemu script hereafter is installed.</li>
<li>This is a python script that carries out network management tasks every time a VM is started, stopped or migrated, as per the Libvirt hooks specification.</li>
<li>Custom network configuration tasks can be done at the same time as the qemu script is called.</li>
<li>Since the tasks in question are user-specific, they cannot be included in the CloudStack-provided qemu script.</li>
<li>The Libvirt documentation page <a class="reference external" href="https://libvirt.org/hooks.html#qemu">qemu</a> describes the parameters that can be passed to the qemu script, based on what actions KVM and Libvirt are carrying out on each VM: ‘prepare’, ‘start’, ‘started’, ‘stopped’, ‘release’, ‘migrate’, ‘restore’, ‘reconnect’ and ‘attach’.</li>
</ul>
</div>
<div class="section" id="the-kvm-libvirt-hook-script-allows-for">
<h2>The KVM Libvirt Hook script allows for<a class="headerlink" href="hosts.html#the-kvm-libvirt-hook-script-allows-for" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>The inclusion and execution of custom scripts to perform additional networking configuration tasks.</li>
<li>The included custom scripts can be bash scripts and/or python scripts.</li>
<li>Each custom script’s start-up and return commands are captured and logged.</li>
<li>There are no limits to the number of custom scripts that can be included or called.</li>
</ol>
</div>
<div class="section" id="usage">
<h2>Usage<a class="headerlink" href="hosts.html#usage" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p class="first">The cloudstack-agent package will install the qemu script in the /etc/libvirt/hooks directory of Libvirt.</p>
</li>
<li><p class="first">The Libvirt documentation page <a class="reference external" href="https://libvirt.org/hooks.html#arguments">arguments</a> describes the arguments that can be passed to the qemu script.</p>
</li>
<li><p class="first">The input arguments are:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Name of the object involved in the operation, or ‘-‘ if there is none. For example, the name of a guest being started.</li>
<li>Name of the operation being performed. For example, ‘start’ if a guest is being started.</li>
<li>Sub-operation indication, or ‘-‘ if there is none.</li>
<li>An extra argument string, or ‘-‘ if there is none.</li>
</ol>
</div></blockquote>
</li>
<li><p class="first">The operation argument is based on what actions KVM and Libvirt are carrying out on each VM: ‘prepare’, ‘start’, ‘started’, ‘stopped’, ‘release’, ‘migrate’, ‘restore’, ‘reconnect’, ‘attach’.</p>
</li>
<li><p class="first">If an invalid operation argument is received, the qemu script will log the fact, not execute any custom scripts and exit.</p>
</li>
<li><p class="first">All input arguments that are passed to the qemu script will also be passed to each custom script.</p>
</li>
<li><p class="first">For each of the above actions, the qemu script will find and run scripts by the name “&lt;action&gt;_&lt;custom script name&gt;” in a custom include path /etc/libvirt/hooks/custom/. Custom scripts that do not follow this naming convention will be ignored and not be executed.</p>
</li>
<li><p class="first">In addition to the Libvirt standard actions, the qemu script will also find and run custom scripts with an “all” prefixed to the script name. For example: “all_&lt;custom script name&gt;”. These custom scripts will run every time the qemu script is called with a valid Libvirt action.</p>
</li>
<li><p class="first">In the case of multiple custom scripts, they will be executed in sorted (alphabetical) order. The alphabetical ordering will use the file name part after the prefix and underscore have been removed from the file name. For example, if there are two custom script files in the directory: all_cde.sh, migrate_abc.py; they will be sorted and executed in this order: migrate_abc.py, all_cde.sh.</p>
</li>
<li><p class="first">Custom scripts can either be bash scripts and/or python scripts.</p>
</li>
<li><p class="first">Custom scripts must be executable by the underlying host operating system. Non-executable scripts will be logged and ignored.</p>
</li>
<li><p class="first">Each custom script’s start-up and return commands will be captured and logged.</p>
</li>
<li><p class="first">During execution of a custom script, the standard out (stdout) and standard error (stderr) outputs of the custom script will be logged (appended) to /var/log/libvirt/qemu-hook.log. If the custom script needs to log anything, it can also use this file for logging purposes.</p>
</li>
<li><p class="first">There is a timeout setting in the qemu script that counts down at the start of every execution of a custom script. If the custom script is still executing after the timeout time has elapsed, the custom script will be gracefully terminated.</p>
</li>
</ul>
</div>
<div class="section" id="timeout-configuration">
<h2>Timeout Configuration<a class="headerlink" href="hosts.html#timeout-configuration" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p class="first">The timeout setting called “timeoutSeconds”, at the top of the qemu script, has a default timeout setting of 10 minutes, expressed as 10 * 60 seconds, and can be manually modified if a different timeout is required.</p>
</li>
<li><p class="first">To configure a different timeout, do the following:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Navigate to the /etc/libvirt/hooks/ folder.</li>
<li>Open the qemu script in an editor.</li>
<li>Find the “timeoutSeconds” timeout setting.</li>
<li>Change the 10 * 60 value to a preferred timeout value. For example 20 * 60, for a 20-minute timeout.</li>
</ol>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="custom-script-naming-for-a-specific-vm-action">
<h2>Custom Script Naming for a Specific VM Action<a class="headerlink" href="hosts.html#custom-script-naming-for-a-specific-vm-action" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p class="first">For a custom script that needs to be executed at the end of a specific VM action, do the following:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Navigate to the custom script that needs to be executed for a specific action.</li>
<li>Rename the file by prefixing to the filename the specific action name followed by an underscore. For example, if a custom script is named abc.sh, then prefix ‘migrate’ and an underscore to the name to become migrate_abc.sh.</li>
</ol>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="custom-script-naming-for-all-vm-actions">
<h2>Custom Script Naming for All VM Actions<a class="headerlink" href="hosts.html#custom-script-naming-for-all-vm-actions" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p class="first">For a custom script that needs to be executed at the end of all VM actions, do the following:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Navigate to the custom script that needs to be executed for all actions.</li>
<li>Rename the file by prefixing ‘all’ to the filename, followed by an underscore.  For example, if a custom script is named def.py, then prefix ‘all’ and an underscore to the name to become all_def.py.</li>
</ol>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="custom-script-execution-configuration">
<h2>Custom Script Execution Configuration<a class="headerlink" href="hosts.html#custom-script-execution-configuration" title="Permalink to this headline">¶</a></h2>
<ul>
<li><p class="first">Grant each custom script execute permissions so that the underlying host operating system can execute them:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Navigate to the custom script that needs to be executable.</li>
<li>Grant the custom script execute permissions.</li>
</ol>
</div></blockquote>
</li>
<li><p class="first">Place the custom scripts in the custom include folder /etc/libvirt/hooks/custom/ so that the qemu script will be able to find and execute them:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Make sure that the /etc/libvirt/hooks/custom/ folder is created and that it has the correct access permissions.</li>
<li>Navigate to the custom scripts that need to be copied.</li>
<li>Copy the scripts to the /etc/libvirt/hooks/custom/ folder.</li>
</ol>
</div></blockquote>
</li>
<li><p class="first">In shell custom scripts include #!/bin/bash in the first line of the file so that the script will be executed with bash.</p>
</li>
<li><p class="first">In Python custom scripts include #!/usr/bin/python in the first line of the file so that the script will be executed with python.</p>
</li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="storage.html" class="btn btn-neutral float-right" title="存储概述" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="templates.html" class="btn btn-neutral float-left" title="创建模板: 概述" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018, Apache Foundation
      
        <span class="commit">
          Revision <code>7c5c9b49</code>.
        </span>
      

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
      <span class="fa fa-book"> Read the Docs</span>
      v: 4.11.3.0
      <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
      <dl>
        <dt>Versions</dt>
        
          <dd><a href="../../../index.html">latest</a></dd>
        
          <dd><a href="../../4.12.0.0/index.html">4.12.0.0</a></dd>
        
          <dd><a href="../index.html">4.11.3.0</a></dd>
        
          <dd><a href="../../4.11.2.0/index.html">4.11.2.0</a></dd>
        
          <dd><a href="../../4.11.1.0/index.html">4.11.1.0</a></dd>
        
          <dd><a href="http://docs.cloudstack.apache.org/en/master/">master</a></dd>
        
      </dl>
      <dl>
        <dt>Downloads</dt>
        
      </dl>
      <dl>
        <dt>On Read the Docs</dt>
          <dd>
            <a href="http://readthedocs.org/projects/cloudstack-documentation/?fromdocs=cloudstack-documentation">Project Home</a>
          </dd>
          <dd>
            <a href="http://readthedocs.org/builds/cloudstack-documentation/?fromdocs=cloudstack-documentation">Builds</a>
          </dd>
      </dl>
      <hr/>
      Free document hosting provided by <a href="http://www.readthedocs.org">Read the Docs</a>.

    </div>
  </div>



  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
   

</body>
</html>